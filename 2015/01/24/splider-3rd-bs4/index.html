<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python爬虫基础3-BeautifulSoup4 | Sean&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在前一节我们主要讲了如图抓取受限制网站,这一节将会介绍爬虫神兵利器BeautifulSoup4.主要包含以下内容:

安装BeautifulSoup4小试牛刀总结

1.安装BeautifulSoup4
easy_install安装方式,easy_install需要提前安装
easy_install beautifulsoup4
pip安装方式,pip也需要提前安装.此外PyPi中还有一个名字是">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫基础3-BeautifulSoup4">
<meta property="og:url" content="http://blog.xiaolud.com/2015/01/24/splider-3rd-bs4/">
<meta property="og:site_name" content="Sean's blog">
<meta property="og:description" content="在前一节我们主要讲了如图抓取受限制网站,这一节将会介绍爬虫神兵利器BeautifulSoup4.主要包含以下内容:

安装BeautifulSoup4小试牛刀总结

1.安装BeautifulSoup4
easy_install安装方式,easy_install需要提前安装
easy_install beautifulsoup4
pip安装方式,pip也需要提前安装.此外PyPi中还有一个名字是">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫基础3-BeautifulSoup4">
<meta name="twitter:description" content="在前一节我们主要讲了如图抓取受限制网站,这一节将会介绍爬虫神兵利器BeautifulSoup4.主要包含以下内容:

安装BeautifulSoup4小试牛刀总结

1.安装BeautifulSoup4
easy_install安装方式,easy_install需要提前安装
easy_install beautifulsoup4
pip安装方式,pip也需要提前安装.此外PyPi中还有一个名字是">

  
    <link rel="alternative" href="/atom.xml" title="Sean&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/image/favicon.ico">
  
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link href="//libs.useso.com/js/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/style.css" type="text/css">

  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sean&#39;s blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Being-towards-death</a>
        </h2>
      
    </div>
    <div id="header-menu">
      <nav id="main-nav">
        <ul>
        
          <li><a href="/"><i class="fa fa-home icon-setting"></i></a></li>
        
          <li><a href="/archives"><i class="fa fa-archive icon-setting"></i></a></li>
        
          <li><a href="/about"><i class="fa fa-user icon-setting"></i></a></li>
        
        
          <li><a href="/atom.xml"><i class="fa fa-rss %> icon-setting"></i></a></li>
        
        </ul>
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-splider-3rd-bs4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/24/splider-3rd-bs4/" class="article-date">
  <time datetime="2015-01-24T03:14:48.000Z" itemprop="datePublished">Jan 24 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫基础3-BeautifulSoup4
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在前一节我们主要讲了如图抓取受限制网站,这一节将会介绍爬虫神兵利器BeautifulSoup4.<br>主要包含以下内容:</p>
<blockquote>
<p>安装BeautifulSoup4<br>小试牛刀<br>总结</p>
</blockquote>
<h1 id="1-安装BeautifulSoup4">1.安装<strong>BeautifulSoup4</strong></h1>
<p>easy_install安装方式,easy_install需要提前安装</p>
<pre><code><span class="title">easy_install</span> beautifulsoup4
</code></pre><p>pip安装方式,pip也需要提前安装.此外PyPi中还有一个名字是 BeautifulSoup 的包,那是 Beautiful Soup3 的发布版本.在这里不建议安装.</p>
<pre><code>pip <span class="operator"><span class="keyword">install</span> beautifulsoup4</span>
</code></pre><p>Debain或ubuntu安装方式</p>
<pre><code>apt-<span class="keyword">get</span> install Python-bs4
</code></pre><p>你也可以通过源码安装,<a href="http://www.crummy.com/software/BeautifulSoup/bs4/download/4.0/" title="下载BS4源码" target="_blank" rel="external">下载BS4源码</a></p>
<pre><code>Python setup.<span class="keyword">py</span> install
</code></pre><h1 id="2-小试牛刀">2.小试牛刀</h1>
<p>老样子,直接上代码</p>
<pre><code><span class="comment"># coding=utf-8</span>
<span class="string">'''
@通过BeautifulSoup下载百度贴吧图片
'''</span>
<span class="keyword">import</span> urllib
<span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup
url = <span class="string">'http://tieba.baidu.com/p/3537654215'</span>

<span class="comment"># 下载网页</span>
html = urllib.urlopen(url)
content = html.read()
html.close()

<span class="comment"># 使用BeautifulSoup匹配图片</span>
html_soup = BeautifulSoup(content)
<span class="comment"># 图片代码我们在[Python爬虫基础1--urllib]( http://blog.xiaolud.com/2015/01/22/spider-1st/ "Python爬虫基础1--urllib")里面已经分析过了</span>
<span class="comment"># 相较通过正则表达式去匹配,BeautifulSoup提供了一个更简单灵活的方式</span>
all_img_links = html_soup.findAll(<span class="string">'img'</span>, class_=<span class="string">'BDE_Image'</span>)

<span class="comment"># 接下来就是老生常谈的下载图片</span>
img_counter = <span class="number">1</span>
<span class="keyword">for</span> img_link <span class="keyword">in</span> all_img_links:
    img_name = <span class="string">'%s.jpg'</span> % img_counter
    urllib.urlretrieve(img_link[<span class="string">'src'</span>], img_name)
    img_counter += <span class="number">1</span>
</code></pre><p>很简单,代码注释里面已经解释的很清楚了.BeautifulSoup提供了一个更简单灵活的方式,去分析网站源码,更快获取图片link.</p>
<h1 id="3-总结">3.总结</h1>
<pre><code>未完待续
</code></pre>
      
    </div>
    <footer class="article-footer">
      
        <a href="http://blog.xiaolud.com/2015/01/24/splider-3rd-bs4/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BeautifulSoup4/">BeautifulSoup4</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bs4/">bs4</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spider/">spider</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/01/29/spider-4th-doubantop100/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Python爬虫基础4-豆瓣top100
        
      </div>
    </a>
  
  
    <a href="/2015/01/23/spider-2nd-urllib2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Python爬虫基础2--urllib2</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
        
      </div>
    </div>
    
    
<script>
  var disqus_shortname = 'xiaolud';
  
  var disqus_url = 'http://blog.xiaolud.com/2015/01/24/splider-3rd-bs4/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="http://libs.useso.com/js/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js" type="text/javascript"></script>


  </div>
</body>
</html>
